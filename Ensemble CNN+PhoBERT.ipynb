{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb8bc34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:35:37.873902Z",
          "iopub.status.busy": "2023-05-05T03:35:37.873381Z",
          "iopub.status.idle": "2023-05-05T03:35:46.291139Z",
          "shell.execute_reply": "2023-05-05T03:35:46.290124Z"
        },
        "papermill": {
          "duration": 8.426706,
          "end_time": "2023-05-05T03:35:46.293409",
          "exception": false,
          "start_time": "2023-05-05T03:35:37.866703",
          "status": "completed"
        },
        "tags": [],
        "id": "7fb8bc34",
        "outputId": "c53f204c-637d-4416-dad3-04289526b39b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x76ef806aa9b0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import time, datetime, random, optuna, re, string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.cuda.amp import autocast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from transformers import BertModel, BertTokenizer, AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from string import ascii_lowercase\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 15\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cda401",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:35:46.304147Z",
          "iopub.status.busy": "2023-05-05T03:35:46.302718Z",
          "iopub.status.idle": "2023-05-05T03:35:46.312217Z",
          "shell.execute_reply": "2023-05-05T03:35:46.310573Z"
        },
        "papermill": {
          "duration": 0.018282,
          "end_time": "2023-05-05T03:35:46.316021",
          "exception": false,
          "start_time": "2023-05-05T03:35:46.297739",
          "status": "completed"
        },
        "tags": [],
        "id": "b3cda401"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd053818",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:35:46.333024Z",
          "iopub.status.busy": "2023-05-05T03:35:46.332662Z",
          "iopub.status.idle": "2023-05-05T03:35:46.350768Z",
          "shell.execute_reply": "2023-05-05T03:35:46.348321Z"
        },
        "papermill": {
          "duration": 0.029783,
          "end_time": "2023-05-05T03:35:46.354096",
          "exception": false,
          "start_time": "2023-05-05T03:35:46.324313",
          "status": "completed"
        },
        "tags": [],
        "id": "dd053818"
      },
      "outputs": [],
      "source": [
        "def clean(data):\n",
        "    data = data.lower() \n",
        "    with open('/kaggle/input/datacomments/teencode.txt','r') as file:\n",
        "      file = file.read()\n",
        "      lines = file.split('\\n')\n",
        "      for line in lines:\n",
        "        elements = line.split('\\t')\n",
        "        data = re.sub(r'\\b{}+\\b'.format(elements[0]), elements[1], data)\n",
        "    alphabet = 'abcdefghijlmnopqrstuvwxyz'\n",
        "    for c in alphabet:\n",
        "      data = re.sub(r'{}+'.format(c), c, data)\n",
        "    data = re.sub(r'\\s+', ' ', data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfcbaa10",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:35:46.366543Z",
          "iopub.status.busy": "2023-05-05T03:35:46.366002Z",
          "iopub.status.idle": "2023-05-05T03:36:02.069423Z",
          "shell.execute_reply": "2023-05-05T03:36:02.068458Z"
        },
        "papermill": {
          "duration": 15.712267,
          "end_time": "2023-05-05T03:36:02.071877",
          "exception": false,
          "start_time": "2023-05-05T03:35:46.359610",
          "status": "completed"
        },
        "tags": [],
        "id": "cfcbaa10"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_excel('../input/datacomments/train.xlsx')\n",
        "df_test =  pd.read_excel('../input/datacomments/test.xlsx')\n",
        "df_valid = pd.read_excel('../input/datacomments/valid.xlsx')\n",
        "\n",
        "\n",
        "train_texts = df_train['Sentence'].apply(clean)\n",
        "test_texts = df_test['Sentence'].apply(clean)\n",
        "valid_texts = df_valid['Sentence'].apply(clean)\n",
        "\n",
        "y= LabelEncoder()\n",
        "\n",
        "train_labels = y.fit_transform(df_train['Emotion'])\n",
        "valid_labels = y.fit_transform(df_valid['Emotion'])\n",
        "test_labels = y.fit_transform(df_test['Emotion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b94143",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:02.082095Z",
          "iopub.status.busy": "2023-05-05T03:36:02.081781Z",
          "iopub.status.idle": "2023-05-05T03:36:02.089666Z",
          "shell.execute_reply": "2023-05-05T03:36:02.088658Z"
        },
        "papermill": {
          "duration": 0.015351,
          "end_time": "2023-05-05T03:36:02.092023",
          "exception": false,
          "start_time": "2023-05-05T03:36:02.076672",
          "status": "completed"
        },
        "tags": [],
        "id": "80b94143"
      },
      "outputs": [],
      "source": [
        "model_name =   'vinai/phobert-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1904fcb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:02.100748Z",
          "iopub.status.busy": "2023-05-05T03:36:02.100491Z",
          "iopub.status.idle": "2023-05-05T03:36:21.529541Z",
          "shell.execute_reply": "2023-05-05T03:36:21.528519Z"
        },
        "papermill": {
          "duration": 19.436306,
          "end_time": "2023-05-05T03:36:21.532085",
          "exception": false,
          "start_time": "2023-05-05T03:36:02.095779",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "ea5fa9bfe6eb49c8a393cac51fd36014",
            "d256d31e07f74a56bfdd443809e67a35",
            "929adfbba8ce4f16aa0dfe66a071c6aa",
            "8942372da0e3430cb8406b2689d0cdb4"
          ]
        },
        "id": "f1904fcb",
        "outputId": "4cd4619f-0b84-4619-fb8f-3f7cf3781dea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea5fa9bfe6eb49c8a393cac51fd36014",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d256d31e07f74a56bfdd443809e67a35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "929adfbba8ce4f16aa0dfe66a071c6aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8942372da0e3430cb8406b2689d0cdb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, output_hidden_states=True).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97282f40",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:21.543448Z",
          "iopub.status.busy": "2023-05-05T03:36:21.543107Z",
          "iopub.status.idle": "2023-05-05T03:36:22.648734Z",
          "shell.execute_reply": "2023-05-05T03:36:22.647801Z"
        },
        "papermill": {
          "duration": 1.113702,
          "end_time": "2023-05-05T03:36:22.651068",
          "exception": false,
          "start_time": "2023-05-05T03:36:21.537366",
          "status": "completed"
        },
        "tags": [],
        "id": "97282f40"
      },
      "outputs": [],
      "source": [
        "max_length = 256\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt' )\n",
        "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "\n",
        "\n",
        "# https://huggingface.co/transformers/v3.4.0/custom_datasets.html\n",
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "\n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)\n",
        "test_dataset = NewsGroupsDataset(test_encodings, test_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836b67c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:22.662099Z",
          "iopub.status.busy": "2023-05-05T03:36:22.661258Z",
          "iopub.status.idle": "2023-05-05T03:36:22.671429Z",
          "shell.execute_reply": "2023-05-05T03:36:22.670605Z"
        },
        "papermill": {
          "duration": 0.017662,
          "end_time": "2023-05-05T03:36:22.673399",
          "exception": false,
          "start_time": "2023-05-05T03:36:22.655737",
          "status": "completed"
        },
        "tags": [],
        "id": "836b67c6"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes):\n",
        "        super().__init__()\n",
        "        num_classes = num_classes  # number of targets to predict\n",
        "#         output_channel = 52  # number of kernels\n",
        "        output_channel = 32\n",
        "        dropout = 0.4  # dropout value\n",
        "        embedding_dim = 768  # length of embedding dim\n",
        "\n",
        "        ks = 3  # three conv nets here\n",
        "\n",
        "        input_channel = 4\n",
        "        # [3, 4, 5] = window height\n",
        "        # padding = padding to account for height of search window\n",
        "\n",
        "        # 3 convolutional nets\n",
        "        self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim),  padding=(2, 0), groups=input_channel)\n",
        "        self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim),  padding=(3, 0), groups=input_channel)\n",
        "        self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim),  padding=(4, 0), groups=input_channel)\n",
        "        #stride=(1, 1),\n",
        "        # apply dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fully connected layer for classification\n",
        "        # 3x conv nets * output channel\n",
        "        self.fc1 = nn.Linear(ks * output_channel, num_classes)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        # squeeze to get size; (batch, channel_output, ~=sent_len) * ks\n",
        "        x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n",
        "        # max-over-time pooling; # (batch, channel_output) * ks\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        # concat results; (batch, channel_output * ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        # add dropout\n",
        "        x = self.dropout(x)\n",
        "        # generate logits (batch, target_size)\n",
        "        logit = self.fc1(x)\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c668840a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:22.683636Z",
          "iopub.status.busy": "2023-05-05T03:36:22.683381Z",
          "iopub.status.idle": "2023-05-05T03:36:22.701131Z",
          "shell.execute_reply": "2023-05-05T03:36:22.700170Z"
        },
        "papermill": {
          "duration": 0.025275,
          "end_time": "2023-05-05T03:36:22.703133",
          "exception": false,
          "start_time": "2023-05-05T03:36:22.677858",
          "status": "completed"
        },
        "tags": [],
        "id": "c668840a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train(model, dataloader, optimizer):\n",
        "\n",
        "    # reset total loss for epoch\n",
        "    train_total_loss = 0\n",
        "\n",
        "    # put both models into traning mode\n",
        "    model.train()\n",
        "    CNN_model.train()\n",
        "\n",
        "    # for each batch of training data...\n",
        "    for step, batch in enumerate(dataloader):\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "        # clear previously calculated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # runs the forward pass with autocasting.\n",
        "        with autocast():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "           \n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "\n",
        "\n",
        "            hidden_layers = hidden_layers[:, -4 :]\n",
        "#             hidden_layers = hidden_layers[:, :]\n",
        "\n",
        "        logits = CNN_model(hidden_layers)\n",
        "        loss = criterion(logits, b_labels.view(-1))\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        # Updates the scale for next iteration.\n",
        "        scaler.update()\n",
        "\n",
        "        # Update the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # calculate preds\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "\n",
        "        # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "\n",
        "\n",
        "    # calculate the average loss over all of the batches\n",
        "    avg_train_loss = train_total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'Train Loss': avg_train_loss,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def validating(model, dataloader):\n",
        "    # put both models in evaluation mode\n",
        "    model.eval()\n",
        "    CNN_model.eval()\n",
        "\n",
        "    total_valid_loss = 0\n",
        "    total_accuracy=0\n",
        "    # evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "\n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "#             hidden_layers = hidden_layers[:, :]\n",
        "            hidden_layers = hidden_layers[:, -4 :]\n",
        "\n",
        "        logits = CNN_model(hidden_layers)\n",
        "        loss = criterion(logits, b_labels.view(-1))\n",
        "        \n",
        "        _, predicted = torch.max(logits, 1)\n",
        "      # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "\n",
        "        # accumulate validation loss\n",
        "        total_valid_loss += loss.item()\n",
        "        total_accuracy += accuracy_score(predicted, y_true)\n",
        "\n",
        "    avg_val_loss = total_valid_loss / len(dataloader)\n",
        "    avg_accuracy = total_accuracy / len(dataloader)\n",
        "    # Record all statistics from this epoch.\n",
        "    valid_stats.append(\n",
        "        {\n",
        "            'Val Loss': avg_val_loss,\n",
        "            'Accuracy': avg_accuracy,\n",
        "            \n",
        "        }\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def testing(model, CNN_model, dataloader):\n",
        "    # put both models in evaluation mode\n",
        "    y_pred = []\n",
        "\n",
        "    # evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "\n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "\n",
        "#             hidden_layers = hidden_layers[:,:]\n",
        "            hidden_layers = hidden_layers[:, -4 :]\n",
        "\n",
        "        logits = CNN_model(hidden_layers)\n",
        "\n",
        "        # calculate preds\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "\n",
        "        # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "        \n",
        "        for i in predicted:\n",
        "            y_pred.append(i)\n",
        "\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaecdc12",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:22.712600Z",
          "iopub.status.busy": "2023-05-05T03:36:22.712337Z",
          "iopub.status.idle": "2023-05-05T03:36:22.725872Z",
          "shell.execute_reply": "2023-05-05T03:36:22.725085Z"
        },
        "papermill": {
          "duration": 0.020646,
          "end_time": "2023-05-05T03:36:22.727994",
          "exception": false,
          "start_time": "2023-05-05T03:36:22.707348",
          "status": "completed"
        },
        "tags": [],
        "id": "eaecdc12"
      },
      "outputs": [],
      "source": [
        "# instantiate CNN\n",
        "CNN_model = CNN(num_classes=7).cuda()\n",
        "\n",
        "# set loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# set number of epochs\n",
        "epochs = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.1) \n",
        "\n",
        "# set LR scheduler\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "# create gradient scaler for mixed precision\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe0b7ef",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T03:36:22.737798Z",
          "iopub.status.busy": "2023-05-05T03:36:22.737544Z",
          "iopub.status.idle": "2023-05-05T04:43:09.237012Z",
          "shell.execute_reply": "2023-05-05T04:43:09.235976Z"
        },
        "papermill": {
          "duration": 4006.51084,
          "end_time": "2023-05-05T04:43:09.243034",
          "exception": false,
          "start_time": "2023-05-05T03:36:22.732194",
          "status": "completed"
        },
        "tags": [],
        "id": "ebe0b7ef",
        "outputId": "5b267bb9-6595-45ea-f75b-4496eb1988a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "epoch | train loss | val loss | accuracy\n",
            "    1 | 1.66298    | 1.37487  | 0.526\n",
            "    2 | 1.20973    | 1.16461  | 0.596\n",
            "    3 | 0.88538    | 1.15403  | 0.608\n",
            "    4 | 0.63486    | 1.20952  | 0.611\n",
            "    5 | 0.46729    | 1.24075  | 0.605\n"
          ]
        }
      ],
      "source": [
        "training_stats = []\n",
        "valid_stats = []\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = 0\n",
        "timeline = []\n",
        "\n",
        "# for each epoch\n",
        "print('Training...')\n",
        "print(\"epoch | train loss | val loss | accuracy\")\n",
        "for epoch in range(epochs):\n",
        "    time_start = time.time()\n",
        "    # train\n",
        "    train(model, train_dataloader, optimizer)\n",
        "    # validate\n",
        "    validating(model, valid_dataloader)\n",
        "    print(f\"{epoch+1:5d} | {training_stats[epoch]['Train Loss']:<10.5f} | {valid_stats[epoch]['Val Loss']:<8.5f} | {valid_stats[epoch]['Accuracy']:<5.3f}\")\n",
        "    if valid_stats[epoch]['Accuracy'] > best_valid_acc:\n",
        "        best_valid_acc = valid_stats[epoch]['Accuracy']\n",
        "        torch.save(CNN_model.state_dict(), 'cnn-model.pt')  # torch save\n",
        "        torch.save(model.state_dict(), 'bert-cnn-model.pt')\n",
        "        model.save_pretrained('./model_save/bert-cnn/') \n",
        "    time_end = time.time()\n",
        "    timeline.append(time_end - time_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ab9a5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T04:43:09.253760Z",
          "iopub.status.busy": "2023-05-05T04:43:09.253462Z",
          "iopub.status.idle": "2023-05-05T04:43:12.458906Z",
          "shell.execute_reply": "2023-05-05T04:43:12.457990Z"
        },
        "papermill": {
          "duration": 3.21334,
          "end_time": "2023-05-05T04:43:12.461185",
          "exception": false,
          "start_time": "2023-05-05T04:43:09.247845",
          "status": "completed"
        },
        "tags": [],
        "id": "b5ab9a5c",
        "outputId": "136721a2-5c93-445d-b66f-58efe8073b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.571     0.400     0.471        40\n",
            "           1      0.584     0.659     0.619       132\n",
            "           2      0.673     0.736     0.703       193\n",
            "           3      0.733     0.717     0.725        46\n",
            "           4      0.573     0.550     0.561       129\n",
            "           5      0.735     0.621     0.673       116\n",
            "           6      0.684     0.703     0.693        37\n",
            "\n",
            "    accuracy                          0.645       693\n",
            "   macro avg      0.650     0.627     0.635       693\n",
            "weighted avg      0.646     0.645     0.643       693\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('bert-cnn-model.pt'))\n",
        "CNN_model.load_state_dict(torch.load('cnn-model.pt'))\n",
        "y_pred = testing(model, CNN_model,test_dataloader)\n",
        "print(classification_report(test_dataset[:]['labels'].ravel(),y_pred,digits=3)) #3 # 0.558 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4624bfe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-05T04:43:12.472197Z",
          "iopub.status.busy": "2023-05-05T04:43:12.471914Z",
          "iopub.status.idle": "2023-05-05T04:43:12.478220Z",
          "shell.execute_reply": "2023-05-05T04:43:12.477325Z"
        },
        "papermill": {
          "duration": 0.013861,
          "end_time": "2023-05-05T04:43:12.480182",
          "exception": false,
          "start_time": "2023-05-05T04:43:12.466321",
          "status": "completed"
        },
        "tags": [],
        "id": "d4624bfe",
        "outputId": "ac23336d-34eb-4415-a96a-695fb90682b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[801.9382066726685,\n",
              " 801.9325015544891,\n",
              " 801.6724972724915,\n",
              " 802.166387796402,\n",
              " 798.7817034721375]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4065.984486,
      "end_time": "2023-05-05T04:43:15.903017",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-05-05T03:35:29.918531",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
