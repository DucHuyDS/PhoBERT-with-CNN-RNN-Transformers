{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import time, datetime, random, optuna, re, string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.cuda.amp import autocast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from transformers import BertModel, BertTokenizer, AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from string import ascii_lowercase\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 15\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:00.901417Z",
          "iopub.execute_input": "2023-05-04T13:50:00.901912Z",
          "iopub.status.idle": "2023-05-04T13:50:12.169499Z",
          "shell.execute_reply.started": "2023-05-04T13:50:00.901870Z",
          "shell.execute_reply": "2023-05-04T13:50:12.168427Z"
        },
        "trusted": true,
        "id": "HNJqTKmBaqKw",
        "outputId": "b9a90ea4-fcb9-4eb5-c3cb-4588ca18ccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch._C.Generator at 0x7d3cf260f170>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:12.171822Z",
          "iopub.execute_input": "2023-05-04T13:50:12.172500Z",
          "iopub.status.idle": "2023-05-04T13:50:12.179006Z",
          "shell.execute_reply.started": "2023-05-04T13:50:12.172454Z",
          "shell.execute_reply": "2023-05-04T13:50:12.178103Z"
        },
        "trusted": true,
        "id": "eYlKy0dSaqK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(data):\n",
        "    data = data.lower() \n",
        "    with open('/kaggle/input/datacomments/teencode.txt','r') as file:\n",
        "      file = file.read()\n",
        "      lines = file.split('\\n')\n",
        "      for line in lines:\n",
        "        elements = line.split('\\t')\n",
        "        data = re.sub(r'\\b{}+\\b'.format(elements[0]), elements[1], data)\n",
        "    alphabet = 'abcdefghijlmnopqrstuvwxyz'\n",
        "    for c in alphabet:\n",
        "      data = re.sub(r'{}+'.format(c), c, data)\n",
        "    data = re.sub(r'\\s+', ' ', data)\n",
        "    return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:12.180309Z",
          "iopub.execute_input": "2023-05-04T13:50:12.180817Z",
          "iopub.status.idle": "2023-05-04T13:50:12.193974Z",
          "shell.execute_reply.started": "2023-05-04T13:50:12.180781Z",
          "shell.execute_reply": "2023-05-04T13:50:12.192989Z"
        },
        "trusted": true,
        "id": "slwnbllAaqK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_excel('../input/datacomments/train.xlsx')\n",
        "df_test =  pd.read_excel('../input/datacomments/test.xlsx')\n",
        "df_valid = pd.read_excel('../input/datacomments/valid.xlsx')\n",
        "\n",
        "\n",
        "train_texts = df_train['Sentence'].apply(clean)\n",
        "test_texts = df_test['Sentence'].apply(clean)\n",
        "valid_texts = df_valid['Sentence'].apply(clean)\n",
        "\n",
        "y= LabelEncoder()\n",
        "\n",
        "train_labels = y.fit_transform(df_train['Emotion'])\n",
        "valid_labels = y.fit_transform(df_valid['Emotion'])\n",
        "test_labels = y.fit_transform(df_test['Emotion'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:12.196985Z",
          "iopub.execute_input": "2023-05-04T13:50:12.197418Z",
          "iopub.status.idle": "2023-05-04T13:50:28.098392Z",
          "shell.execute_reply.started": "2023-05-04T13:50:12.197383Z",
          "shell.execute_reply": "2023-05-04T13:50:28.097380Z"
        },
        "trusted": true,
        "id": "WmO-PTLsaqK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name =   'vinai/phobert-base'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:28.099955Z",
          "iopub.execute_input": "2023-05-04T13:50:28.100687Z",
          "iopub.status.idle": "2023-05-04T13:50:28.111430Z",
          "shell.execute_reply.started": "2023-05-04T13:50:28.100649Z",
          "shell.execute_reply": "2023-05-04T13:50:28.110489Z"
        },
        "trusted": true,
        "id": "HtpqcKnkaqK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, output_hidden_states=True).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:28.112855Z",
          "iopub.execute_input": "2023-05-04T13:50:28.113287Z",
          "iopub.status.idle": "2023-05-04T13:50:42.290310Z",
          "shell.execute_reply.started": "2023-05-04T13:50:28.113250Z",
          "shell.execute_reply": "2023-05-04T13:50:42.289265Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7808ce5f104c41e98b734c15c7c3a43d",
            "8c6b119457d04849b91237004058f283",
            "c0a98db734e44f7096d7667f51b09d3c",
            "96c596d14986464db207e16cdea7b50a"
          ]
        },
        "id": "hLFIe09QaqK9",
        "outputId": "97daa648-43d3-4cd1-b235-2fa962ec343d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7808ce5f104c41e98b734c15c7c3a43d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c6b119457d04849b91237004058f283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0a98db734e44f7096d7667f51b09d3c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96c596d14986464db207e16cdea7b50a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt' )\n",
        "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "\n",
        "\n",
        "# https://huggingface.co/transformers/v3.4.0/custom_datasets.html\n",
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "\n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)\n",
        "test_dataset = NewsGroupsDataset(test_encodings, test_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=8,\n",
        "                              shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:42.291739Z",
          "iopub.execute_input": "2023-05-04T13:50:42.292391Z",
          "iopub.status.idle": "2023-05-04T13:50:43.329259Z",
          "shell.execute_reply.started": "2023-05-04T13:50:42.292352Z",
          "shell.execute_reply": "2023-05-04T13:50:43.328250Z"
        },
        "trusted": true,
        "id": "yPjsuw1taqK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        num_classes = num_classes\n",
        "        hidden_size = 128\n",
        "        dropout = 0.4\n",
        "        embedding_dim = 768\n",
        "        num_layers = 1  # Increase the number of layers to 3\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True, dropout =dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        mean_x = torch.mean(x, dim=1, keepdim=True)\n",
        "        batch_size, num_models, seq_len, hidden_size = mean_x.shape\n",
        "        x = mean_x.reshape(batch_size*num_models, seq_len, hidden_size)\n",
        "#         x = x.transpose(1,0)\n",
        "        \n",
        "        x, _ = self.rnn(x)\n",
        "        \n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x.transpose(1, 2), x.size(1)).squeeze(2)\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        logit = self.fc1(x)\n",
        "        return logit"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:50:43.330902Z",
          "iopub.execute_input": "2023-05-04T13:50:43.331289Z",
          "iopub.status.idle": "2023-05-04T13:50:43.340904Z",
          "shell.execute_reply.started": "2023-05-04T13:50:43.331248Z",
          "shell.execute_reply": "2023-05-04T13:50:43.339823Z"
        },
        "trusted": true,
        "id": "yNk2YeUXaqLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer):\n",
        "\n",
        "    # reset total loss for epoch\n",
        "    train_total_loss = 0\n",
        "\n",
        "    # put both models into traning mode\n",
        "    model.train()\n",
        "    RNN_model.train()\n",
        "    # for each batch of training data...\n",
        "    for step, batch in enumerate(dataloader):\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "        # clear previously calculated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # runs the forward pass with autocasting.\n",
        "        with autocast():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "\n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "\n",
        "\n",
        "\n",
        "            hidden_layers = hidden_layers[:, :]\n",
        "\n",
        "        logits = RNN_model(hidden_layers)\n",
        "        loss = criterion(logits, b_labels.view(-1))\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        # Updates the scale for next iteration.\n",
        "        scaler.update()\n",
        "\n",
        "        # Update the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # calculate preds\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "\n",
        "        # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "\n",
        "        # calculate f1\n",
        "\n",
        "\n",
        "    # calculate the average loss over all of the batches\n",
        "    avg_train_loss = train_total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'Train Loss': avg_train_loss,\n",
        "        }\n",
        "    )\n",
        "    #torch.cuda.empty_cache()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def validating(model, dataloader):\n",
        "    # put both models in evaluation mode\n",
        "    model.eval()\n",
        "    RNN_model.eval()\n",
        "    total_valid_loss = 0\n",
        "    total_accuracy=0\n",
        "    # evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "\n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "            hidden_layers = hidden_layers[:, :]\n",
        "\n",
        "        logits = RNN_model(hidden_layers)\n",
        "        loss = criterion(logits, b_labels.view(-1))\n",
        "        \n",
        "        _, predicted = torch.max(logits, 1)\n",
        "      # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "\n",
        "        # accumulate validation loss\n",
        "        total_valid_loss += loss.item()\n",
        "        total_accuracy += accuracy_score(predicted, y_true)\n",
        "\n",
        "    avg_val_loss = total_valid_loss / len(dataloader)\n",
        "    avg_accuracy = total_accuracy / len(dataloader)\n",
        "    # Record all statistics from this epoch.\n",
        "    valid_stats.append(\n",
        "        {\n",
        "            'Val Loss': avg_val_loss,\n",
        "            'Accuracy': avg_accuracy,\n",
        "            \n",
        "        }\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def testing(model, RNN_model,dataloader):\n",
        "    # put both models in evaluation mode\n",
        "    y_pred = []\n",
        "\n",
        "    # evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "\n",
        "        b_input_ids = batch['input_ids'].cuda()\n",
        "        b_input_mask = batch['attention_mask'].cuda()\n",
        "        b_labels = batch['labels'].cuda().long()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_layers = outputs['hidden_states']  # get hidden layers\n",
        "\n",
        "            hidden_layers = torch.stack(hidden_layers, dim=1)  # stack the layers\n",
        "\n",
        "            hidden_layers = hidden_layers[:,:]\n",
        "\n",
        "        logits = RNN_model(hidden_layers)\n",
        "\n",
        "        # calculate preds\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "\n",
        "        # move logits and labels to CPU\n",
        "        predicted = predicted.detach().cpu().numpy()\n",
        "        y_true = b_labels.detach().cpu().numpy().ravel()\n",
        "        \n",
        "        for i in predicted:\n",
        "            y_pred.append(i)\n",
        "\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:52:21.370715Z",
          "iopub.execute_input": "2023-05-04T13:52:21.371071Z",
          "iopub.status.idle": "2023-05-04T13:52:21.389957Z",
          "shell.execute_reply.started": "2023-05-04T13:52:21.371041Z",
          "shell.execute_reply": "2023-05-04T13:52:21.388768Z"
        },
        "trusted": true,
        "id": "4I4YFQ53aqLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate CNN\n",
        "RNN_model = RNN(num_classes=7).cuda()\n",
        "\n",
        "# set loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# set number of epochs\n",
        "epochs = 5\n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr=5e-5)  #weight_decay \n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.1) \n",
        "\n",
        "# set LR scheduler\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "# create gradient scaler for mixed precision\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:52:22.270747Z",
          "iopub.execute_input": "2023-05-04T13:52:22.271523Z",
          "iopub.status.idle": "2023-05-04T13:52:23.169357Z",
          "shell.execute_reply.started": "2023-05-04T13:52:22.271486Z",
          "shell.execute_reply": "2023-05-04T13:52:23.168313Z"
        },
        "trusted": true,
        "id": "yXCnlXRtaqLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_stats = []\n",
        "valid_stats = []\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = 0\n",
        "timeline = []\n",
        "\n",
        "# for each epoch\n",
        "print('Training...')\n",
        "print(\"epoch | train loss | val loss | accuracy\")\n",
        "for epoch in range(epochs):\n",
        "    time_start = time.time()\n",
        "    # train\n",
        "    train(model, train_dataloader, optimizer)\n",
        "    # validate\n",
        "    validating(model, valid_dataloader)\n",
        "    print(f\"{epoch+1:5d} | {training_stats[epoch]['Train Loss']:<10.5f} | {valid_stats[epoch]['Val Loss']:<8.5f} | {valid_stats[epoch]['Accuracy']:<5.3f}\")\n",
        "    if valid_stats[epoch]['Accuracy'] > best_valid_acc:\n",
        "        best_valid_acc = valid_stats[epoch]['Accuracy']\n",
        "        torch.save(RNN_model.state_dict(), 'rnn-model.pt')  # torch save\n",
        "        torch.save(model.state_dict(), 'bert-rnn-model.pt')\n",
        "        model.save_pretrained('./model_save/bert-rnn/') \n",
        "    time_end = time.time()\n",
        "    timeline.append(time_end - time_start)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T13:52:24.497857Z",
          "iopub.execute_input": "2023-05-04T13:52:24.498809Z",
          "iopub.status.idle": "2023-05-04T14:03:15.633520Z",
          "shell.execute_reply.started": "2023-05-04T13:52:24.498756Z",
          "shell.execute_reply": "2023-05-04T14:03:15.632261Z"
        },
        "trusted": true,
        "id": "UWuDKZToaqLH",
        "outputId": "a2b087a1-a2ae-4c97-e6d3-f9037df1de2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Training...\nepoch | train loss | val loss | accuracy\n    1 | 1.57742    | 1.35280  | 0.540\n    2 | 1.21103    | 1.29414  | 0.561\n    3 | 0.98453    | 1.26258  | 0.587\n    4 | 0.80168    | 1.21835  | 0.599\n    5 | 0.70111    | 1.24444  | 0.582\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('bert-rnn-model.pt'))\n",
        "RNN_model.load_state_dict(torch.load('rnn-model.pt'))\n",
        "y_pred = testing(model, RNN_model,test_dataloader)\n",
        "print(classification_report(test_dataset[:]['labels'].ravel(),y_pred,digits=3)) #3 # 0.558 "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T14:03:15.637086Z",
          "iopub.execute_input": "2023-05-04T14:03:15.637379Z",
          "iopub.status.idle": "2023-05-04T14:03:18.211780Z",
          "shell.execute_reply.started": "2023-05-04T14:03:15.637348Z",
          "shell.execute_reply": "2023-05-04T14:03:18.210423Z"
        },
        "trusted": true,
        "id": "KnIhj1KYaqLI",
        "outputId": "026f57b5-8477-4c25-c165-c3c98f048f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0      0.462     0.450     0.456        40\n           1      0.589     0.674     0.629       132\n           2      0.690     0.705     0.697       193\n           3      0.692     0.587     0.635        46\n           4      0.578     0.574     0.576       129\n           5      0.725     0.638     0.679       116\n           6      0.649     0.649     0.649        37\n\n    accuracy                          0.638       693\n   macro avg      0.627     0.611     0.617       693\nweighted avg      0.641     0.638     0.638       693\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timeline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T14:03:18.213625Z",
          "iopub.execute_input": "2023-05-04T14:03:18.214048Z",
          "iopub.status.idle": "2023-05-04T14:03:18.221475Z",
          "shell.execute_reply.started": "2023-05-04T14:03:18.214004Z",
          "shell.execute_reply": "2023-05-04T14:03:18.220245Z"
        },
        "trusted": true,
        "id": "Elrnno1MaqLJ",
        "outputId": "a28c01e2-36bf-4f1f-c147-a7ce52dba59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[131.21999382972717,\n 130.83610653877258,\n 130.3486773967743,\n 130.4610631465912,\n 128.2597906589508]"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
